import { describe, it, expect } from "vitest";
import { CsvFileInput } from "@/core/io/file";
import { GraphFactory } from "@/core/loading";
import { Concurrency } from "@/concurrency";

/**
 * ğŸ¯ FOCUSED IMPORT ANALYSIS - importNodes() Method Breakdown
 *
 * This tool dissects the importNodes() method to understand:
 * 1. ğŸ“‹ Schema loading and validation
 * 2. ğŸ—ï¸ NodesBuilder configuration
 * 3. ğŸ­ Visitor pattern setup
 * 4. ğŸ§µ Parallel processing execution
 * 5. ğŸ“Š Node construction and statistics
 *
 * Focus: Understanding EXACTLY what importNodes() does step-by-step
 */

const REFERENCE_STORE_PATH = "/home/pat/VSCode/neovm/src/tools/reference-graphstore";

describe("ğŸ¯ importNodes() Method Analysis", () => {

  it("ğŸ“‹ STEP 1: Schema Loading and Validation", () => {
    console.log("ğŸ“‹ === SCHEMA LOADING ANALYSIS ===");

    const csvInput = new CsvFileInput(REFERENCE_STORE_PATH);

    // âœ… This is exactly what importNodes() does first:
    const nodeSchema = csvInput.nodeSchema();

    console.log("ğŸ” Schema Analysis:");
    console.log(`  ğŸ“Š Schema type: ${nodeSchema.constructor.name}`);
    console.log(`  ğŸ·ï¸ Available labels: ${nodeSchema.availableLabels().length}`);

    // Log each label like importNodes() does
    const nodeLabels = Array.from(nodeSchema.availableLabels());
    console.log(`ğŸ“‹ Node labels (${nodeLabels.length}): ${nodeLabels.map(l => l.name()).join(", ")}`);

    // Log schema entries like importNodes() does
    for (const entry of nodeSchema.entries()) {
      console.log(`  ğŸ“Š Node label schema: ${entry.identifier()}`);
      // Dig deeper into what each entry contains
      console.log(`    ğŸ”§ Entry type: ${entry.constructor.name}`);
    }

    expect(nodeSchema).toBeTruthy();
    expect(nodeLabels.length).toBeGreaterThan(0);
  });

  it("ğŸ·ï¸ STEP 2: Label Mapping Analysis", () => {
    console.log("ğŸ·ï¸ === LABEL MAPPING ANALYSIS ===");

    const csvInput = new CsvFileInput(REFERENCE_STORE_PATH);

    // âœ… This is the label mapping logic from importNodes():
    const labelMapping = csvInput.labelMapping();

    if (labelMapping) {
      console.log(`ğŸ·ï¸ Label mappings found: ${labelMapping.size} entries`);
      for (const [key, value] of labelMapping) {
        console.log(`  ğŸ·ï¸ Label mapping: ${key} -> ${value}`);
      }
    } else {
      console.log("ğŸ·ï¸ Label mapping file was not found, continuing without label mapping");
    }

    // This reveals how label mapping works (or doesn't work)
    console.log("ğŸ” Label mapping impact:");
    console.log("  âœ… Optional feature - import continues without it");
    console.log("  ğŸ¯ Probably used for label transformation during import");
  });

  it("ğŸ—ï¸ STEP 3: NodesBuilder Configuration", () => {
    console.log("ğŸ—ï¸ === NODESBUILDER CONFIGURATION ===");

    const csvInput = new CsvFileInput(REFERENCE_STORE_PATH);
    const nodeSchema = csvInput.nodeSchema();
    const graphInfo = csvInput.graphInfo();
    const concurrency = Concurrency.of(1);

    console.log("ğŸ” GraphInfo for NodesBuilder:");
    console.log(`  ğŸ“Š Max original ID: ${graphInfo.maxOriginalId()}`);
    console.log(`  ğŸ“Š Node count: ${graphInfo.nodeCount()}`);
    console.log(`  ğŸ”§ ID map builder type: ${graphInfo.idMapBuilderType()}`);

    // âœ… This is the exact NodesBuilder setup from importNodes():
    try {
      const nodesBuilder = GraphFactory.initNodesBuilder(nodeSchema)
        .maxOriginalId(graphInfo.maxOriginalId())
        .concurrency(concurrency)
        .nodeCount(graphInfo.nodeCount())
        .deduplicateIds(false)
        .idMapBuilderType(graphInfo.idMapBuilderType())
        .build();

      console.log("âœ… NodesBuilder created successfully");
      console.log(`  ğŸ”§ Builder type: ${nodesBuilder.constructor.name}`);

      // Analyze the builder configuration
      console.log("ğŸ¯ Builder Configuration:");
      console.log(`  ğŸ§µ Concurrency: ${concurrency.value()}`);
      console.log(`  ğŸ“Š Expected node count: ${graphInfo.nodeCount()}`);
      console.log(`  ğŸ”‘ ID deduplication: false`);
      console.log(`  ğŸ—‚ï¸ ID map type: ${graphInfo.idMapBuilderType()}`);

    } catch (error) {
      console.log(`âŒ NodesBuilder creation failed: ${(error as Error).message}`);
      console.log("ğŸ” This reveals the exact configuration requirements");
    }
  });

  it("ğŸ­ STEP 4: Visitor Pattern Setup", () => {
    console.log("ğŸ­ === VISITOR PATTERN SETUP ===");

    const csvInput = new CsvFileInput(REFERENCE_STORE_PATH);
    const nodeSchema = csvInput.nodeSchema();

    console.log("ğŸ” Visitor Builder Configuration:");
    console.log("  ğŸ“‹ Input: NodeSchema");
    console.log("  ğŸ—ï¸ Input: NodesBuilder");
    console.log("  ğŸ¯ Output: GraphStoreNodeVisitor");

    // This is what importNodes() does with the visitor builder:
    console.log("ğŸ­ Visitor Builder Pattern:");
    console.log("  1. nodeVisitorBuilder.withNodeSchema(nodeSchema)");
    console.log("  2. nodeVisitorBuilder.withNodesBuilder(nodesBuilder)");
    console.log("  3. nodeVisitorBuilder.build() â†’ GraphStoreNodeVisitor");

    console.log("ğŸ”§ Visitor Purpose:");
    console.log("  âœ… Receives CSV data via visitor methods");
    console.log("  âœ… Converts CSV rows to internal node format");
    console.log("  âœ… Populates NodesBuilder with parsed data");
    console.log("  âœ… Handles property type conversion");
    console.log("  âœ… Manages ID mapping and validation");
  });

  it("ğŸ§µ STEP 5: Parallel Processing Setup", () => {
    console.log("ğŸ§µ === PARALLEL PROCESSING SETUP ===");

    const csvInput = new CsvFileInput(REFERENCE_STORE_PATH);
    const concurrency = Concurrency.of(2);

    console.log("ğŸ” Parallel Processing Analysis:");
    console.log(`  ğŸ§µ Concurrency level: ${concurrency.value()}`);
    console.log("  ğŸ“¦ Iterator: csvInput.nodes().iterator()");
    console.log("  ğŸƒ Runner: ElementImportRunner");
    console.log("  ğŸ‘¥ Tasks: ParallelUtil.tasks()");
    console.log("  âš¡ Execution: ParallelUtil.run()");

    // This is the parallel processing pattern from importNodes():
    console.log("ğŸ¯ Parallel Execution Flow:");
    console.log("  1. Create nodes iterator");
    console.log("  2. Create multiple ElementImportRunner tasks");
    console.log("  3. Each task processes chunks in parallel");
    console.log("  4. All tasks use same visitor builder (thread-safe)");
    console.log("  5. ParallelUtil coordinates execution");
    console.log("  6. Progress tracker monitors completion");

    // Test iterator creation
    const nodesIterator = csvInput.nodes().iterator();
    console.log(`âœ… Nodes iterator created: ${nodesIterator.constructor.name}`);
  });

  it("ğŸ“Š STEP 6: Node Construction and Statistics", () => {
    console.log("ğŸ“Š === NODE CONSTRUCTION ANALYSIS ===");

    const csvInput = new CsvFileInput(REFERENCE_STORE_PATH);
    const graphInfo = csvInput.graphInfo();

    console.log("ğŸ” Construction Process:");
    console.log("  1. ğŸ­ Visitor processes all CSV chunks");
    console.log("  2. ğŸ—ï¸ NodesBuilder accumulates node data");
    console.log("  3. ğŸ“Š nodesBuilder.build() creates final Nodes");
    console.log("  4. ğŸ¯ graphStoreBuilder.nodes(nodes) sets nodes");
    console.log("  5. ğŸ“ˆ Statistics updated with counts and timing");

    // Expected output statistics
    console.log("ğŸ“ˆ Expected Statistics:");
    console.log(`  ğŸ‘¥ Nodes imported: ${graphInfo.nodeCount()}`);
    console.log(`  ğŸ“ Node files processed: 1 (or actual file count)`);
    console.log(`  â±ï¸ Import time: measured in milliseconds`);
    console.log(`  ğŸ“Š Nodes per second: calculated rate`);

    // Final result
    console.log("ğŸ¯ Final Output:");
    console.log("  âœ… Nodes object with complete node store");
    console.log("  âœ… ID mapping for relationship processing");
    console.log("  âœ… Property storage with type safety");
    console.log("  âœ… Label-based node organization");
  });

  it("ğŸ”§ STEP 7: Error Handling and Cleanup", () => {
    console.log("ğŸ”§ === ERROR HANDLING ANALYSIS ===");

    console.log("ğŸš¨ Error Scenarios in importNodes():");
    console.log("  1. ğŸ“ File access errors during iteration");
    console.log("  2. ğŸ“‹ Schema validation failures");
    console.log("  3. ğŸ—ï¸ NodesBuilder configuration errors");
    console.log("  4. ğŸ§µ Parallel processing exceptions");
    console.log("  5. ğŸ’¾ Memory allocation failures");

    console.log("ğŸ›¡ï¸ Error Handling Strategy:");
    console.log("  âœ… Try-catch around parallel processing");
    console.log("  âœ… Error count increment on failures");
    console.log("  âœ… Progress tracker failure notification");
    console.log("  âœ… Detailed error logging");
    console.log("  âœ… Exception re-throwing for caller handling");

    console.log("ğŸ§¹ Cleanup Operations:");
    console.log("  âœ… Progress tracker endSubTask() on success");
    console.log("  âœ… Progress tracker endSubTaskWithFailure() on error");
    console.log("  âœ… Resource cleanup in finally blocks");
  });

  it("ğŸ¯ COMPLETE importNodes() FLOW SUMMARY", () => {
    console.log("ğŸ¯ === COMPLETE FLOW SUMMARY ===");

    console.log("ğŸ“‹ importNodes() Complete Process:");
    console.log("  1. ğŸ“‹ Load and validate node schema");
    console.log("  2. ğŸ·ï¸ Handle optional label mapping");
    console.log("  3. ğŸ—ï¸ Configure NodesBuilder with graph info");
    console.log("  4. ğŸ­ Setup visitor with schema and builder");
    console.log("  5. ğŸ§µ Create parallel processing tasks");
    console.log("  6. âš¡ Execute parallel CSV processing");
    console.log("  7. ğŸ“Š Build final Nodes object");
    console.log("  8. ğŸ“ˆ Update statistics and timing");
    console.log("  9. ğŸ›¡ï¸ Handle errors and cleanup");
    console.log("  10. âœ… Return Nodes with ID mapping");

    console.log("ğŸ¯ Key Insights:");
    console.log("  âœ… Schema-driven processing ensures type safety");
    console.log("  âœ… Parallel processing scales with concurrency");
    console.log("  âœ… Visitor pattern abstracts CSV details");
    console.log("  âœ… NodesBuilder handles memory optimization");
    console.log("  âœ… ID mapping enables relationship processing");
    console.log("  âœ… Statistics provide performance monitoring");
  });

});
